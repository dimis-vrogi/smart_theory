import streamlit as st
from docx import Document
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity


st.set_page_config(
    page_title="Smart Theory Matcher",
    layout="centered"
)

st.title(" Smart Theory Matcher")
st.write("Î•Ï€Î¹ÎºÏŒÎ»Î»Î·ÏƒÎµ Î¼Î¹Î± Î¬ÏƒÎºÎ·ÏƒÎ· ÎºÎ±Î¹ Î¸Î± ÏƒÎ¿Ï… ÎµÏ€Î¹ÏƒÏ„ÏÎ­ÏˆÏ‰ Ï„Î¿ Ï€Î¹Î¸Î±Î½ÏŒÏ„ÎµÏÎ¿ ÎºÎµÏ†Î¬Î»Î±Î¹Î¿.")


@st.cache_resource
def load_model():
    return SentenceTransformer(
        "sentence-transformers/all-MiniLM-L6-v2"  # ğŸ”¥ ÎµÎ»Î±Ï†ÏÏ & Î³ÏÎ®Î³Î¿ÏÎ¿
    )

model = load_model()


@st.cache_data
def load_dataset():
    DOC_PATH = "Trapeza.docx"
    doc = Document(DOC_PATH)

    rows = []
    current_chapter = None
    current_exercise = None
    buffer = []

    for p in doc.paragraphs:
        text = p.text.strip()
        if not text:
            continue

        if text.startswith("ÎšÎ•Î¦Î‘Î›Î‘Î™ÎŸ:"):
            current_chapter = text.replace("ÎšÎ•Î¦Î‘Î›Î‘Î™ÎŸ:", "").strip()

        elif text.startswith("Î˜Î•ÎœÎ‘"):
            if current_exercise and buffer and current_chapter:
                chapters = [c.strip() for c in current_chapter.split(",")]
                for ch in chapters:
                    rows.append({
                        "exercise_text": " ".join(buffer),
                        "chapter": ch
                    })
            current_exercise = text
            buffer = []

        else:
            buffer.append(text)

    if current_exercise and buffer and current_chapter:
        chapters = [c.strip() for c in current_chapter.split(",")]
        for ch in chapters:
            rows.append({
                "exercise_text": " ".join(buffer),
                "chapter": ch
            })

    df = pd.DataFrame(rows)
    df = df[df["chapter"] != "Î‘Î“ÎÎ©Î£Î¤ÎŸ ÎšÎ•Î¦Î‘Î›Î‘Î™ÎŸ"].reset_index(drop=True)
    return df

df = load_dataset()

st.success(f"Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ {len(df)} Î±ÏƒÎºÎ®ÏƒÎµÎ¹Ï‚")


@st.cache_data
def compute_embeddings(texts):
    return model.encode(texts)

df["emb"] = list(compute_embeddings(df["exercise_text"].tolist()))


chapter_embeddings = {}

for chapter, group in df.groupby("chapter"):
    embs = np.vstack(group["emb"].values)
    chapter_embeddings[chapter] = embs.mean(axis=0)


def predict_best_chapter(text):
    query_emb = model.encode([text])[0]

    best_chapter = None
    best_score = -1.0

    for chapter, chap_emb in chapter_embeddings.items():
        sim = cosine_similarity(
            query_emb.reshape(1, -1),
            chap_emb.reshape(1, -1)
        )[0][0]

        if sim > best_score:
            best_score = float(sim)
            best_chapter = chapter

    return best_chapter, best_score


user_text = st.text_area(
    " Î•Ï€Î¹ÎºÏŒÎ»Î»Î·ÏƒÎµ Ï„Î·Î½ Î¬ÏƒÎºÎ·ÏƒÎ· ÎµÎ´Ï:",
    height=180
)

if st.button(" Î‘Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎµ ÎšÎµÏ†Î¬Î»Î±Î¹Î¿"):
    if user_text.strip():
        chapter, score = predict_best_chapter(user_text)

        st.subheader(" Î Î¹Î¸Î±Î½ÏŒÏ„ÎµÏÎ¿ ÎšÎµÏ†Î¬Î»Î±Î¹Î¿")
        st.write(f"**{chapter}**")
        st.caption(f"Similarity score: {score:.3f}")
    else:
        st.warning("Î“ÏÎ¬ÏˆÎµ Ï€ÏÏÏ„Î± Î¼Î¹Î± Î¬ÏƒÎºÎ·ÏƒÎ·.")
